{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8aa2edb-69d3-4a65-88c4-848c9e3c52cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:56:34.776375Z",
     "iopub.status.busy": "2024-06-20T12:56:34.776139Z",
     "iopub.status.idle": "2024-06-20T12:56:39.189618Z",
     "shell.execute_reply": "2024-06-20T12:56:39.189106Z",
     "shell.execute_reply.started": "2024-06-20T12:56:34.776356Z"
    },
    "id": "a8aa2edb-69d3-4a65-88c4-848c9e3c52cf",
    "outputId": "7391bcf3-14ec-4f12-b067-b640b9799fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.20.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.5)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.15.10)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.39.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.11/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (69.0.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.23.4)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.1+cu121)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=c5c289ebcb52a24ecabd4c335b5ebc71fab42c6ce31118946220cfbbd48d8d4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, evaluate\n",
      "Successfully installed evaluate-0.4.2 rouge_score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers huggingface_hub datasets wandb evaluate rouge_score accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0d4aab-4542-40ac-ba5c-ceaf16dd3bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:56:39.190724Z",
     "iopub.status.busy": "2024-06-20T12:56:39.190547Z",
     "iopub.status.idle": "2024-06-20T12:56:56.332408Z",
     "shell.execute_reply": "2024-06-20T12:56:56.331981Z",
     "shell.execute_reply.started": "2024-06-20T12:56:39.190707Z"
    },
    "id": "7d0d4aab-4542-40ac-ba5c-ceaf16dd3bca",
    "outputId": "ed9cefcc-0130-4c15-acb3-3869e729387e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:56:45.812137: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 12:56:45.812196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 12:56:45.814142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 12:56:45.896969: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 12:56:47.028025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f1ef3a-6cbf-4543-97f2-4cc0892edc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:56:56.333339Z",
     "iopub.status.busy": "2024-06-20T12:56:56.333083Z",
     "iopub.status.idle": "2024-06-20T12:57:07.292958Z",
     "shell.execute_reply": "2024-06-20T12:57:07.292437Z",
     "shell.execute_reply.started": "2024-06-20T12:56:56.333325Z"
    },
    "id": "f4f1ef3a-6cbf-4543-97f2-4cc0892edc5a"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter you hugging face token:  ·····································\n",
      "Enter your wandb key:  ········································\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass(\"Enter you hugging face token: \")\n",
    "wandb_key = getpass(\"Enter your wandb key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f909a7-bccd-4c56-8ca6-80d5825c07e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:07.294347Z",
     "iopub.status.busy": "2024-06-20T12:57:07.294163Z",
     "iopub.status.idle": "2024-06-20T12:57:08.917261Z",
     "shell.execute_reply": "2024-06-20T12:57:08.916696Z",
     "shell.execute_reply.started": "2024-06-20T12:57:07.294330Z"
    },
    "id": "44f909a7-bccd-4c56-8ca6-80d5825c07e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)\n",
    "wandb.login(key=wandb_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a2ea31-1b9b-4697-bfdd-e5cb474084f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:08.918380Z",
     "iopub.status.busy": "2024-06-20T12:57:08.917974Z",
     "iopub.status.idle": "2024-06-20T12:57:09.229002Z",
     "shell.execute_reply": "2024-06-20T12:57:09.228522Z",
     "shell.execute_reply.started": "2024-06-20T12:57:08.918364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc5ea82e1a8447181376c42809b8b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53e9ef9dd6346e7b11fe9af426ceddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac5c15e8f2148138026ae01148e0082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['simple', 'medical'],\n",
       "        num_rows: 6967\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "data_files = 'created_simplification_data.json'\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98f6e29-acbb-4f38-a512-87bcc8c5a23f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:09.229884Z",
     "iopub.status.busy": "2024-06-20T12:57:09.229690Z",
     "iopub.status.idle": "2024-06-20T12:57:09.241836Z",
     "shell.execute_reply": "2024-06-20T12:57:09.241342Z",
     "shell.execute_reply.started": "2024-06-20T12:57:09.229884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['simple', 'medical'],\n",
       "        num_rows: 5573\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['simple', 'medical'],\n",
       "        num_rows: 696\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['simple', 'medical'],\n",
       "        num_rows: 698\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset['train']\n",
    "\n",
    "num_samples = len(dataset)\n",
    "num_train = int(0.8 * num_samples)\n",
    "num_val = int(0.1 * num_samples)\n",
    "num_test = num_samples - num_train - num_val\n",
    "\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "train_dataset = shuffled_dataset.select(range(num_train))\n",
    "val_dataset = shuffled_dataset.select(range(num_train, num_train + num_val))\n",
    "test_dataset = shuffled_dataset.select(range(num_train + num_val, num_samples))\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'valid': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e9744e-de18-4fb2-b5ae-d1284b038d5d",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "2715176f3e99427089d12d2e2df5f74f",
      "782dd2b447224c6f9408d6af2310dc02",
      "dcf0b89b1ce149dba7db6ba5f56a3737",
      "73cd491865b14d5084924ef835e0b936",
      "5123e366b0bb41ed863bc359c294b03d"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:09.242669Z",
     "iopub.status.busy": "2024-06-20T12:57:09.242536Z",
     "iopub.status.idle": "2024-06-20T12:57:14.217988Z",
     "shell.execute_reply": "2024-06-20T12:57:14.217274Z",
     "shell.execute_reply.started": "2024-06-20T12:57:09.242653Z"
    },
    "id": "62e9744e-de18-4fb2-b5ae-d1284b038d5d",
    "outputId": "befa3352-5355-4ad8-e61c-359b665e39ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d7ba67a870481ea103c2bebcfa6a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11f05f9fcf44336b63a25de5bb8a8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e30d6670e54b3a92bdb013702806d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b30c13eb05400f88b0e2568aceef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae25c0f9317344bda297d90376582991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google-t5/t5-base\"\n",
    "new_model = \"t5-base-ft-medical-simplifier\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c633421e-c2f5-4a72-af93-015f53422c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:14.218961Z",
     "iopub.status.busy": "2024-06-20T12:57:14.218767Z",
     "iopub.status.idle": "2024-06-20T12:57:14.222541Z",
     "shell.execute_reply": "2024-06-20T12:57:14.221915Z",
     "shell.execute_reply.started": "2024-06-20T12:57:14.218915Z"
    },
    "id": "c633421e-c2f5-4a72-af93-015f53422c45"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [f\"simplify: {medical_text}\" for medical_text in examples['medical']]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n",
    "\n",
    "    targets = [simple_text for simple_text in examples['simple']]\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=512, truncation=True, padding='max_length')\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faea9d79-22c3-42e9-abee-91dc39311316",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9303eee887b04167a3e75b7dd2fe8907",
      "3783c7bd86f449d7a0578614156c9506",
      "19387ca9b46f41a5955196938e1c6ea3"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:14.223348Z",
     "iopub.status.busy": "2024-06-20T12:57:14.223175Z",
     "iopub.status.idle": "2024-06-20T12:57:16.112894Z",
     "shell.execute_reply": "2024-06-20T12:57:16.112444Z",
     "shell.execute_reply.started": "2024-06-20T12:57:14.223335Z"
    },
    "id": "faea9d79-22c3-42e9-abee-91dc39311316",
    "outputId": "51e1cac3-181b-40f4-ac0b-12a8374cc922"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3234d158b494aab80159831b0b9c094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc842cf4adc34cfc8d64739ccd8391c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/696 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93c1b03b6c41c3b528bfffcf64ef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_dict.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab19209-34d7-4ee6-9f9e-9176b332d7b5",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "345eebd2c3064a6391b8731eca7fb4ae"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:16.114948Z",
     "iopub.status.busy": "2024-06-20T12:57:16.114771Z",
     "iopub.status.idle": "2024-06-20T12:57:16.912095Z",
     "shell.execute_reply": "2024-06-20T12:57:16.911640Z",
     "shell.execute_reply.started": "2024-06-20T12:57:16.114932Z"
    },
    "id": "6ab19209-34d7-4ee6-9f9e-9176b332d7b5",
    "outputId": "34959a0a-915d-4957-edd2-32008fc431b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250e052e208d48e6b5d4d56f50eef633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(\n",
    "      predictions=decoded_preds,\n",
    "      references=decoded_labels,\n",
    "      use_stemmer=True,\n",
    "      rouge_types=[\n",
    "          'rouge1',\n",
    "          'rouge2',\n",
    "          'rougeL'\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb7eb65-5831-4a89-a8af-147450f32428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:16.914513Z",
     "iopub.status.busy": "2024-06-20T12:57:16.914357Z",
     "iopub.status.idle": "2024-06-20T12:57:16.917579Z",
     "shell.execute_reply": "2024-06-20T12:57:16.917069Z",
     "shell.execute_reply.started": "2024-06-20T12:57:16.914498Z"
    },
    "id": "efb7eb65-5831-4a89-a8af-147450f32428"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf60453-10a8-41e2-b822-16fdf25e36b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:16.919749Z",
     "iopub.status.busy": "2024-06-20T12:57:16.919612Z",
     "iopub.status.idle": "2024-06-20T12:57:18.865116Z",
     "shell.execute_reply": "2024-06-20T12:57:18.864620Z",
     "shell.execute_reply.started": "2024-06-20T12:57:16.919735Z"
    },
    "id": "1bf60453-10a8-41e2-b822-16fdf25e36b9",
    "outputId": "c2f3636c-1a02-47db-ee60-593546de2046"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"]=\"t5_base_ft_medical_simplifier\"\n",
    "\n",
    "# save your trained model checkpoint to wandb\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='medical_simplifer_t5_base_results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=1000,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to='wandb',\n",
    "    learning_rate=3e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e797-f666-4dfd-9036-76669eb2be43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:57:18.867655Z",
     "iopub.status.busy": "2024-06-20T12:57:18.867519Z"
    },
    "id": "2e77e797-f666-4dfd-9036-76669eb2be43",
    "outputId": "86896bb5-3588-4beb-a3db-301f890e4a8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manishbasnet1600\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240620_125719-z1mmxewg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier/runs/z1mmxewg' target=\"_blank\">divine-surf-3</a></strong> to <a href='https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier' target=\"_blank\">https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier/runs/z1mmxewg' target=\"_blank\">https://wandb.ai/anishbasnet1600/t5_base_ft_medical_simplifier/runs/z1mmxewg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13476' max='13940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13476/13940 1:31:27 < 03:08, 2.46 it/s, Epoch 9.67/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.623400</td>\n",
       "      <td>0.063776</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>22.847700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.037668</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.553600</td>\n",
       "      <td>0.744200</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>0.776700</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.787800</td>\n",
       "      <td>0.612100</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.030482</td>\n",
       "      <td>0.793400</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.029397</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.796600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.027964</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.803600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.027087</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>0.809800</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.025614</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.820700</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>0.675600</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.831600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.838700</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.839100</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.835300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.023030</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.700200</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.838600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.705300</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.845800</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.846700</td>\n",
       "      <td>0.713300</td>\n",
       "      <td>0.843600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>0.848300</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.845100</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.022243</td>\n",
       "      <td>0.847900</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.844600</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.849500</td>\n",
       "      <td>0.717400</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.850200</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>23.849100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['valid'],\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13ed0e-1228-432c-8924-4662115fc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "model.config.use_cache=True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb4f57-ba46-42bf-9ccf-95c98d8302a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(text, model, tokenizer, max_length=512, num_beams=2):\n",
    "    \n",
    "    inputs = tokenizer.encode(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        max_length=max_length,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=1024,\n",
    "        num_beams=num_beams,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193c0847-a827-414e-8cf0-34a53a9d7d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T14:38:55.250785Z",
     "iopub.status.busy": "2024-06-20T14:38:55.250225Z",
     "iopub.status.idle": "2024-06-20T14:38:57.708190Z",
     "shell.execute_reply": "2024-06-20T14:38:57.707703Z",
     "shell.execute_reply.started": "2024-06-20T14:38:55.250753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anishbasnet/t5-base-ft-medical-simplifier/commit/5983c8a36d6e467566fa4f1356e7db05d9df111b', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='5983c8a36d6e467566fa4f1356e7db05d9df111b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "707b4057-5d95-4e6d-85b8-50cc934d2cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T14:39:39.729947Z",
     "iopub.status.busy": "2024-06-20T14:39:39.729363Z",
     "iopub.status.idle": "2024-06-20T14:40:00.260696Z",
     "shell.execute_reply": "2024-06-20T14:40:00.260086Z",
     "shell.execute_reply.started": "2024-06-20T14:39:39.729916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c278abf40ea492fabcca0c8f18052ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16962c7b27847bb81a52bf74266c74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c837c249e45e4a7d8f7cf7644ae6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anishbasnet/medical_simplifer_t5_base_results/commit/c94f4f8221fa85c7e3af62d546aa9df57cf8a7e8', commit_message='t5-base-ft-medical-simplifier', commit_description='', oid='c94f4f8221fa85c7e3af62d546aa9df57cf8a7e8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2951758-8ed1-478b-a26d-804b0d5ef209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T14:46:20.221217Z",
     "iopub.status.busy": "2024-06-20T14:46:20.220593Z",
     "iopub.status.idle": "2024-06-20T14:46:21.810776Z",
     "shell.execute_reply": "2024-06-20T14:46:21.810202Z",
     "shell.execute_reply.started": "2024-06-20T14:46:20.221195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c895dc74a0d4575bce8c925fdb8d1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anishbasnet/t5-base-ft-medical-simplifier/commit/65febfff20dc6af884c6391e6c8b6b4d686ff3bc', commit_message='Upload tokenizer', commit_description='', oid='65febfff20dc6af884c6391e6c8b6b4d686ff3bc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efd170-3b95-464d-b2d0-77167d69c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
